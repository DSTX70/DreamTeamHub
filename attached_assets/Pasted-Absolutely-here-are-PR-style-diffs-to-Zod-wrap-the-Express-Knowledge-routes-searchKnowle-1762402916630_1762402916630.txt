Absolutely — here are **PR-style diffs** to Zod-wrap the **Express Knowledge** routes (`searchKnowledge`, `uploadDraft`) so they mirror the Next.js validators/behavior.

> Apply in Replit with:
>
> ```bash
> git apply -p0 <<'PATCH'
> ...diff...
> PATCH
> ```

---

### 1) Add Zod validators for Knowledge (Express)

```diff
diff --git a/server/lib/validators/knowledge.ts b/server/lib/validators/knowledge.ts
new file mode 100644
--- /dev/null
+++ b/server/lib/validators/knowledge.ts
@@
+import { z } from "zod";
+
+export const OwnerType = z.enum(["BU","BRAND","PRODUCT"]);
+
+export const SearchQuery = z.object({
+  q: z.string().min(2, "q required (min 2 chars)"),
+  limit: z.coerce.number().int().min(1).max(50).optional(),
+});
+export type SearchQuery = z.infer<typeof SearchQuery>;
+
+export const DraftUploadBody = z.object({
+  text: z.string().min(1, "text required"),
+  fileName: z.string()
+    .min(1)
+    .max(255)
+    .regex(/^[^\/\\:*?"<>|]+$/, "invalid filename"),
+  mimeType: z.string().min(3).max(255).optional(),
+});
+export type DraftUploadBody = z.infer<typeof DraftUploadBody>;
```

---

### 2) Zod-wrap the existing **Express Knowledge** routes

```diff
diff --git a/server/api/knowledge.route.ts b/server/api/knowledge.route.ts
--- a/server/api/knowledge.route.ts
+++ b/server/api/knowledge.route.ts
@@
-import type { Request, Response } from "express";
-import crypto from "crypto";
-import { db } from "../drizzle/db";
-import { knowledgeLink, opsEvent } from "../drizzle/schema";
-import { eq, and } from "drizzle-orm";
-import { getDriveClient } from "../integrations/googleDrive_real";
+import type { Request, Response } from "express";
+import crypto from "crypto";
+import { db } from "../drizzle/db";
+import { knowledgeLink, opsEvent } from "../drizzle/schema";
+import { eq, and } from "drizzle-orm";
+import { getDriveClient } from "../integrations/googleDrive_real";
+import { SearchQuery, DraftUploadBody } from "../lib/validators/knowledge";
 
 function required(v: any, msg: string) {
   if (!v) throw Object.assign(new Error(msg), { status: 400 });
 }
@@
 export async function searchKnowledge(req: Request, res: Response) {
   try {
-    const owner = String(req.params.owner).toUpperCase();
-    const id = String(req.params.id);
-    const q = String(req.query.q || "");
-    required(q && q.length >= 2, "q required (min 2 chars)");
+    const owner = String(req.params.owner).toUpperCase();
+    const id = String(req.params.id);
+    const parsed = SearchQuery.safeParse({ q: req.query.q, limit: req.query.limit });
+    if (!parsed.success) {
+      const msg = parsed.error.errors.map(e => e.message).join("; ");
+      return res.status(422).json({ error: msg });
+    }
+    const { q, limit } = parsed.data;
     const { read } = await resolveFolders(owner, id);
     required(read, "KB read folder not linked");
     const drive = getDriveClient();
-    const out = await drive.search(read!, q, Number(req.query.limit ?? 20));
+    const out = await drive.search(read!, q, Number(limit ?? 20));
     return res.json(out);
   } catch (e:any) {
     return res.status(e.status || 500).json({ error: e.message || "search failed" });
   }
 }
 
 export async function uploadDraft(req: Request, res: Response) {
   try {
     const owner = String(req.params.owner).toUpperCase();
     const id = String(req.params.id);
     const { draft } = await resolveFolders(owner, id);
     required(draft, "Drafts folder not linked");
     const drive = getDriveClient();
 
-    // Accept simple text body for stub; replace with multipart parser for files
-    const text = (req.body && typeof req.body === "object" && "text" in req.body) ? (req.body as any).text : "# draft";
-    const name = (req.body && typeof req.body === "object" && "fileName" in req.body) ? (req.body as any).fileName : `draft-${Date.now()}.md`;
+    // Validate body with Zod
+    const parsed = DraftUploadBody.safeParse(req.body || {});
+    if (!parsed.success) {
+      const msg = parsed.error.errors.map(e => e.message).join("; ");
+      return res.status(422).json({ error: msg });
+    }
+    const { text, fileName, mimeType } = parsed.data;
 
-    const file = await drive.upload(draft!, { text, fileName: name, mimeType: "text/markdown" });
+    const file = await drive.upload(draft!, { text, fileName, mimeType: mimeType ?? "text/markdown" });
     // analytics click already captured elsewhere; here we just return file meta
     return res.status(201).json({ ok: true, file });
   } catch (e:any) {
     return res.status(e.status || 500).json({ error: e.message || "upload failed" });
   }
 }
```

---

## Quick tests

```bash
# Search: invalid (too short)
curl "/api/knowledge/BU/<IMAGINATION_ID>/search?q=x" -i
# -> 422 {"error":"q required (min 2 chars)"}

# Search: valid
curl "/api/knowledge/BU/<IMAGINATION_ID>/search?q=calendar&limit=10" -i
# -> 200 with items and X-Total-Count (if you set it upstream)

# Draft upload: invalid filename
curl -XPOST "/api/knowledge/BU/<IMAGINATION_ID>/drafts" \
  -H "content-type: application/json" \
  -d '{"text":"# draft","fileName":"bad/name.md"}' -i
# -> 422 {"error":"invalid filename"}

# Draft upload: valid
curl -XPOST "/api/knowledge/BU/<IMAGINATION_ID>/drafts" \
  -H "content-type: application/json" \
  -d '{"text":"# draft","fileName":"README.md","mimeType":"text/markdown"}' -i
# -> 201 { ok: true, file: {...} }
```

---

## Definition of Done

* ✅ Both **search** and **drafts upload** reject malformed inputs with **422** + human-readable messages.
* ✅ Behavior mirrors your Next.js routes.
* ✅ No change to good-paths; only safer inputs and clearer errors.

If you’d like, I can also add a tiny **filename sanitizer** util (to auto-fix unsafe characters instead of rejecting) or wire `X-Total-Count` on search responses if your Drive layer can surface total estimates.
